{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdb56b1-147e-4ea8-8ca4-c65ca304b958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.24.3 which is incompatible.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d96a883-6273-48db-8ed6-b043c3a51c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0386fe22-7d88-442b-8220-3d380bca3864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palm.configure(api_key='***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce57dfbb-0d23-45eb-bad5-a36628848d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(name='models/text-bison-001', base_model_id='', version='001', display_name='Text Bison', description='Model targeted for text generation.', input_token_limit=8196, output_token_limit=1024, supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'], temperature=0.7, top_p=0.95, top_k=40)]\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aad149f-9e0d-45d6-abf2-7e61b06249f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4103d0b8-698e-4937-9a04-9b660785dbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-thought:\n",
      "First find the total number of cats: 3 houses * 3 cats / house = 9 cats. Then multiply the number of cats by the number of mittens per cat to find the total number of mittens: 9 cats * 4 mittens / cat = 36 mittens. Then multiply the number of mittens by the length of yarn per mitten to find the total length of yarn used for mittens: 36 mittens * 7m / mitten = 252m. Then multiply the number of cats by the number of hats per cat to find the total number of hats: 9 cats * 1 hat / cat = 9 hats. Then multiply the number of hats by the length of yarn per hat to find the total length of yarn used for hats: 9 hats * 4m / hat = 36m. Then add the length of yarn used for mittens and hats to find the total length of yarn used: 252m + 36m = 288m.\n",
      "\n",
      "The answer should be 288\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "You are an expert at solving word problems.\n",
    "\n",
    "Solve the following problem:\n",
    "\n",
    "I have three houses, each with three cats.\n",
    "each cat owns 4 mittens, and a hat. Each mitten was\n",
    "knit from 7m of yarn, each hat from 4m.\n",
    "How much yarn was needed to make all the items?\n",
    "\n",
    "Think about it step by step, and show your work.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "print(completion.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
